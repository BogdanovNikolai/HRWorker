# Логирование запросов к HeadHunter API

## Обзор

Добавлено подробное логирование всех запросов к HeadHunter API для отслеживания параметров поиска, HTTP запросов, ответов и статистики.

## Уровни логирования

### INFO - Основная информация
- Параметры поиска
- HTTP запросы и ответы
- Статистика результатов
- Кэширование

### DEBUG - Детальная информация
- Детали резюме
- Внутренние операции

### WARNING - Предупреждения
- Неполные страницы
- Ошибки кэширования
- Проблемы с токенами

### ERROR - Ошибки
- HTTP ошибки
- Ошибки парсинга
- Сетевые проблемы

## Структура логов

### 1. Параметры поиска

```
=== ПАРАМЕТРЫ ПОИСКА ===
Ключевые слова: python разработчик
Регион: ['2019']
Общее количество: 20
На страницу: 20
Описание: 

--- Текстовые параметры ---
Логика поиска: all
Поле поиска: skills

--- Параметры зарплаты ---
Зарплата от: 100000
Зарплата до: 300000
Валюта: RUR

--- Параметры фильтрации ---
Возраст от: 25
Возраст до: 35
Опыт работы: ['between1And3', 'between3And6']
Тип занятости: ['full']
Пол: male

--- Дополнительные фильтры ---
Сортировка: relevance
Метки: ['only_with_photo']

=== КОНЕЦ ПАРАМЕТРОВ ===
```

### 2. HTTP запросы

```
Выполняется GET-запрос к API HeadHunter: https://api.hh.ru/resumes?text=python%20разработчик&region=2019&salary_from=100000&salary_to=300000&currency=RUR&experience=between1And3&experience=between3And6&employment=full&gender=male&order_by=relevance&label=only_with_photo&page=0&per_page=20
Параметры запроса: {'text': 'python разработчик', 'region': ['2019'], 'salary_from': 100000, 'salary_to': 300000, 'currency': 'RUR', 'experience': ['between1And3', 'between3And6'], 'employment': ['full'], 'gender': 'male', 'order_by': 'relevance', 'label': ['only_with_photo'], 'page': 0, 'per_page': 20}
```

### 3. HTTP ответы

```
Отправляем HTTP запрос к HH API (страница 0)
Получен ответ от HH API: статус 200
Статистика ответа HH API:
  - Найдено всего: 1542
  - Страниц: 78
  - На странице: 20
  - Получено резюме: 20
```

### 4. Кэширование

```
Получены данные из кэша для страницы 0
Неполная страница 1: получено 15 из 20
```

### 5. Детали резюме

```
Запрос деталей резюме: 12345678
Отправляем HTTP запрос для резюме 12345678
Получен ответ для резюме 12345678: статус 200
Детали резюме 12345678:
  - Название: Python разработчик
  - Регион: Москва
  - Зарплата: 150000
Резюме 12345678 сохранено в кэш
```

### 6. Итоговая статистика

```
=== ИТОГИ ПОИСКА ===
Всего загружено резюме: 45
Обработано страниц: 3
Запрошено резюме: 50
=== КОНЕЦ ПОИСКА ===
```

## Файлы логов

### Основной файл
- **Путь**: `logs/app.log`
- **Содержит**: Все логи приложения, включая запросы к HH API

### Структура записи
```
2024-01-17 15:30:45,123 - api.hh.main - INFO - Выполняется GET-запрос к API HeadHunter: https://api.hh.ru/resumes?...
```

## Тестирование логирования

Для тестирования логирования создан скрипт `test_logging.py`:

```bash
python test_logging.py
```

Скрипт выполняет:
1. Простой поиск резюме
2. Поиск с фильтрами
3. Поиск с текстовыми параметрами
4. Получение деталей резюме

## Анализ логов

### Поиск проблем с API
```bash
grep "ERROR" logs/app.log
grep "WARNING" logs/app.log
```

### Анализ производительности
```bash
grep "ИТОГИ ПОИСКА" logs/app.log
grep "Статистика ответа" logs/app.log
```

### Отслеживание кэширования
```bash
grep "кэша" logs/app.log
grep "сохранено в кэш" logs/app.log
```

### Мониторинг токенов
```bash
grep "токен" logs/app.log
grep "лимит" logs/app.log
```

## Настройка логирования

### Уровень логирования
В `utils/logger.py` можно настроить уровень логирования:

```python
# Для отладки
logging.basicConfig(level=logging.DEBUG)

# Для продакшена
logging.basicConfig(level=logging.INFO)
```

### Ротация логов
Логи автоматически ротируются по размеру и времени:

```python
# Максимальный размер файла: 10MB
# Количество файлов: 5
# Формат: app.log, app.log.1, app.log.2, etc.
```

## Мониторинг в реальном времени

### Просмотр логов в реальном времени
```bash
tail -f logs/app.log
```

### Фильтрация по типу запросов
```bash
# Только поиск резюме
tail -f logs/app.log | grep "ПАРАМЕТРЫ ПОИСКА"

# Только HTTP запросы
tail -f logs/app.log | grep "HTTP запрос"

# Только ошибки
tail -f logs/app.log | grep "ERROR"
```

## Примеры использования

### Отладка проблем с поиском
1. Запустите поиск с проблемными параметрами
2. Проверьте логи на наличие ошибок
3. Анализируйте параметры запроса
4. Сравните с ожидаемыми результатами

### Мониторинг производительности
1. Отслеживайте время выполнения запросов
2. Анализируйте статистику ответов
3. Мониторьте использование кэша
4. Следите за лимитами API

### Анализ использования
1. Какие параметры поиска используются чаще
2. Эффективность кэширования
3. Популярные регионы и ключевые слова
4. Статистика ошибок и предупреждений

## Интеграция с системами мониторинга

Логи можно интегрировать с системами мониторинга:

- **ELK Stack** (Elasticsearch, Logstash, Kibana)
- **Grafana + Loki**
- **Splunk**
- **Datadog**

### Пример конфигурации для ELK
```yaml
# logstash.conf
input {
  file {
    path => "/path/to/logs/app.log"
    type => "hh-api-logs"
  }
}

filter {
  grok {
    match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} - %{DATA:logger} - %{LOGLEVEL:level} - %{GREEDYDATA:message}" }
  }
}

output {
  elasticsearch {
    hosts => ["localhost:9200"]
    index => "hh-api-logs-%{+YYYY.MM.dd}"
  }
}
``` 